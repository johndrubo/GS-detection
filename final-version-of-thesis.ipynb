{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10682440,"sourceType":"datasetVersion","datasetId":6617965},{"sourceId":10776965,"sourceType":"datasetVersion","datasetId":6686637}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jedike/final-version-of-thesis?scriptVersionId=224392516\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras import layers, models, applications, callbacks, preprocessing, regularizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Suppress warnings and set plot style\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('ggplot')\n\n# ===================== Configuration =====================\nGS_BASE_PATH = '/kaggle/input/goldenhar/CAPSTR~1'\nHEALTHY_PATH = '/kaggle/input/child-dataset/child/Healthy'\nIMG_SIZE = (256, 256)\nBATCH_SIZE = 32\nSEED = 42\nEPOCHS = 40\n\nSYMPTOM_CLASSES = [\n    'Cleft-Lip-and-Palate',\n    'Epibulbar dermoid tumor',\n    'Eyelid coloboma',\n    'Facial asymmetry',\n    'Malocclusion',\n    'Microtia',\n    'Vertebral abnormality'\n]\nNUM_CLASSES = len(SYMPTOM_CLASSES)\n\n# Create directories for saving plots if they don't exist\nos.makedirs('training_curves', exist_ok=True)\nos.makedirs('confusion_matrices', exist_ok=True)\nos.makedirs('roc_curves', exist_ok=True)\n\n# ===================== Data Visualization =====================\ndef plot_class_distribution(y, title, filename):\n    plt.figure(figsize=(10, 6))\n    sns.countplot(x=y)\n    plt.title(f'Class Distribution - {title}')\n    plt.xlabel('Class')\n    plt.ylabel('Count')\n    plt.savefig(f'class_distribution_{filename}.png')\n    plt.close()\n\ndef plot_training_curves(history, model_name):\n    plt.figure(figsize=(12, 6))\n    \n    # Accuracy plot\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(f'{model_name} Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='lower right')\n    \n    # Loss plot\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(f'{model_name} Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    \n    plt.tight_layout()\n    plt.savefig(f'training_curves/{model_name}.png')\n    plt.close()\n\ndef plot_confusion_matrix(y_true, y_pred, classes, model_name):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=classes, yticklabels=classes)\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.savefig(f'confusion_matrices/{model_name}.png')\n    plt.close()\n\ndef plot_roc_curve(y_true, y_score, model_name):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2,\n             label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - {model_name}')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(f'roc_curves/{model_name}.png')\n    plt.close()\n\n# ===================== Data Loading =====================\ndef load_dataset():\n    gs_images, gs_labels = [], []\n    for class_idx, class_name in enumerate(SYMPTOM_CLASSES):\n        class_dir = os.path.join(GS_BASE_PATH, class_name)\n        images = [os.path.join(class_dir, f) \n                 for f in os.listdir(class_dir)\n                 if f.lower().endswith(('.png','.jpg','.jpeg'))]\n        gs_images.extend(images)\n        gs_labels.extend([class_idx] * len(images))\n        print(f\"Loaded {len(images)} {class_name} images\")\n\n    healthy_images = [os.path.join(HEALTHY_PATH, f) \n                     for f in os.listdir(HEALTHY_PATH)\n                     if f.lower().endswith(('.png','.jpg','.jpeg'))]\n    print(f\"Loaded {len(healthy_images)} healthy images\")\n    \n    return gs_images, gs_labels, healthy_images\n\n# ===================== Data Augmentation =====================\ndef create_generators(X, y, model_type, is_training=False, is_test=False):\n    # Convert labels to strings to satisfy flow_from_dataframe's requirement\n    y = np.array(y).astype(str)\n    df = pd.DataFrame({'filename': X, 'label': y})\n    preprocess_fn = applications.efficientnet.preprocess_input\n\n    if is_training:\n        datagen = preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_fn,\n            rotation_range=40,\n            width_shift_range=0.3,\n            height_shift_range=0.3,\n            shear_range=0.2,\n            zoom_range=0.3,\n            brightness_range=[0.7, 1.3],\n            horizontal_flip=True,\n            vertical_flip=True,\n            fill_mode='nearest',\n            validation_split=0.2\n        )\n        subset = 'training'\n    elif is_test:\n        datagen = preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_fn\n        )\n        subset = None\n    else:\n        datagen = preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_fn,\n            validation_split=0.2\n        )\n        subset = 'validation'\n\n    return datagen.flow_from_dataframe(\n        dataframe=df,\n        x_col='filename',\n        y_col='label',\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode='binary' if model_type == 'binary' else 'sparse',\n        subset=subset,\n        seed=SEED,\n        shuffle=is_training\n    )\n\n# ===================== Regularized Model Architecture =====================\ndef build_model(base_name, num_classes):\n    base_models = {\n        'EfficientNetB0': applications.EfficientNetB0,\n        'ResNet50': applications.ResNet50,\n        'DenseNet121': applications.DenseNet121\n    }\n    \n    base_model = base_models[base_name](\n        include_top=False,\n        weights='imagenet',\n        input_shape=IMG_SIZE + (3,)\n    )\n    \n    # Freeze base model initially\n    base_model.trainable = False\n    \n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(256, activation='relu', \n                    kernel_regularizer=regularizers.l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Dropout(0.6),\n        layers.Dense(128, activation='relu',\n                    kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.5),\n        layers.Dense(1 if num_classes == 2 else num_classes, \n                    activation='sigmoid' if num_classes == 2 else 'softmax')\n    ])\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy' if num_classes == 2 else 'sparse_categorical_crossentropy',\n        metrics=['accuracy', \n                tf.keras.metrics.AUC(name='auc'),\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')]\n    )\n    \n    return model\n\n# ===================== Training Callbacks =====================\ndef get_callbacks(model_name):\n    return [\n        callbacks.EarlyStopping(\n            patience=10,\n            monitor='val_loss',\n            restore_best_weights=True\n        ),\n        callbacks.ModelCheckpoint(\n            f\"best_{model_name}.keras\",\n            save_best_only=True,\n            monitor='val_loss'\n        ),\n        callbacks.ReduceLROnPlateau(\n            factor=0.2,\n            patience=5,\n            min_lr=1e-7\n        )\n    ]\n\n# ===================== Training Pipeline =====================\ndef train_pipeline():\n    gs_images, gs_labels, healthy_images = load_dataset()\n    \n    # Plot initial class distribution for binary classification (GS vs Healthy)\n    plot_class_distribution(\n        np.array([1]*len(gs_images) + [0]*len(healthy_images)),\n        'Full Dataset (GS vs Healthy)', 'full_dataset'\n    )\n    \n    # ----- Binary Classification Setup -----\n    X = np.array(gs_images + healthy_images)\n    y = np.array([1]*len(gs_images) + [0]*len(healthy_images))\n    \n    # Split data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, stratify=y, random_state=SEED\n    )\n    \n    # Calculate class weights for imbalanced data\n    class_counts = np.bincount(y_train)\n    class_weights = {0: 1/class_counts[0], 1: 1/class_counts[1]}\n    \n    print(\"\\n=== Training GS Detection Models ===\")\n    models_list = ['EfficientNetB0', 'ResNet50', 'DenseNet121']\n    \n    for model_name in models_list:\n        print(f\"\\nTraining {model_name} for GS detection...\")\n        \n        # Create training and validation generators for binary classification\n        train_gen = create_generators(X_train, y_train, 'binary', is_training=True)\n        val_gen = create_generators(X_train, y_train, 'binary')\n        \n        # Build and train initial model\n        model = build_model(model_name, 2)\n        history = model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=EPOCHS,\n            class_weight=class_weights,\n            callbacks=get_callbacks(f\"gs_{model_name}\"),\n            verbose=2\n        )\n        plot_training_curves(history, f'gs_{model_name}_phase1')\n        \n        # Fine-tuning: unfreeze part of the base model\n        model.layers[0].trainable = True\n        for layer in model.layers[0].layers[:-10]:\n            layer.trainable = False\n            \n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(1e-6),\n            loss=model.loss,\n            metrics=['accuracy',\n                    tf.keras.metrics.AUC(name='auc'),\n                    tf.keras.metrics.Precision(name='precision'),\n                    tf.keras.metrics.Recall(name='recall')]\n        )\n        \n        history_fine = model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=EPOCHS + 20,\n            initial_epoch=history.epoch[-1],\n            class_weight=class_weights,\n            callbacks=get_callbacks(f\"gs_fine_{model_name}\"),\n            verbose=2\n        )\n        plot_training_curves(history_fine, f'gs_{model_name}_phase2')\n        \n        # Evaluate GS detection model on test set\n        test_gen = create_generators(X_test, y_test, 'binary', is_test=True)\n        y_pred = model.predict(test_gen)\n        y_pred_class = (y_pred > 0.5).astype(int)\n        \n        # Generate evaluation plots\n        plot_confusion_matrix(y_test, y_pred_class, ['Healthy', 'GS'], f'gs_{model_name}')\n        plot_roc_curve(y_test, y_pred, f'gs_{model_name}')\n        \n        print(f\"\\n{model_name} GS Detection Classification Report:\")\n        print(classification_report(y_test, y_pred_class, target_names=['Healthy', 'GS']))\n    \n    # ----- Symptom Classification Setup -----\n    print(\"\\n=== Training Symptom Classifier ===\")\n    sampler = RandomOverSampler()\n    X_res, y_res = sampler.fit_resample(np.array(gs_images).reshape(-1, 1), gs_labels)\n    plot_class_distribution(y_res, 'After Oversampling', 'symptoms_oversampled')\n    \n    for model_name in models_list:\n        print(f\"\\nTraining {model_name} for symptom classification...\")\n        train_gen = create_generators(X_res.flatten(), y_res, 'symptom', is_training=True)\n        val_gen = create_generators(X_res.flatten(), y_res, 'symptom')\n        \n        model = build_model(model_name, NUM_CLASSES)\n        history = model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=EPOCHS,\n            callbacks=get_callbacks(f\"symptom_{model_name}\"),\n            verbose=2\n        )\n        plot_training_curves(history, f'symptom_{model_name}')\n        \n        # Evaluate on a test split for symptom classification\n        _, X_test_sym, _, y_test_sym = train_test_split(\n            gs_images, gs_labels, test_size=0.2, stratify=gs_labels, random_state=SEED\n        )\n        test_gen = create_generators(X_test_sym, y_test_sym, 'symptom', is_test=True)\n        y_pred_sym = np.argmax(model.predict(test_gen), axis=1)\n        \n        # Generate evaluation plots for symptom classifier\n        plot_confusion_matrix(y_test_sym, y_pred_sym, SYMPTOM_CLASSES, f'symptom_{model_name}')\n        \n        print(f\"\\n{model_name} Symptom Classification Report:\")\n        print(classification_report(y_test_sym, y_pred_sym, target_names=SYMPTOM_CLASSES))\n\n# ===================== Model Evaluation Helper Functions =====================\ndef evaluate_gs_model(model_path, X_test, y_test):\n    model = tf.keras.models.load_model(model_path)\n    test_gen = create_generators(X_test, y_test, 'binary', is_test=True)\n    y_pred = model.predict(test_gen)\n    y_pred_class = (y_pred > 0.5).astype(int).flatten()\n    acc = accuracy_score(y_test, y_pred_class)\n    prec = precision_score(y_test, y_pred_class)\n    rec = recall_score(y_test, y_pred_class)\n    f1 = f1_score(y_test, y_pred_class)\n    auc_val = roc_auc_score(y_test, y_pred)\n    return acc, prec, rec, f1, auc_val\n\ndef evaluate_symptom_model(model_path, X_test_sym, y_test_sym):\n    model = tf.keras.models.load_model(model_path)\n    test_gen = create_generators(X_test_sym, y_test_sym, 'symptom', is_test=True)\n    y_pred = model.predict(test_gen)\n    y_pred_class = np.argmax(y_pred, axis=1)\n    report = classification_report(y_test_sym, y_pred_class, target_names=SYMPTOM_CLASSES, output_dict=True)\n    return report\n\n# ===================== Model Comparison =====================\ndef compare_models():\n    # Prepare test sets for evaluation\n    gs_images, gs_labels, healthy_images = load_dataset()\n    X = np.array(gs_images + healthy_images)\n    y = np.array([1]*len(gs_images) + [0]*len(healthy_images))\n    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n    \n    # For symptom classification\n    _, X_test_sym, _, y_test_sym = train_test_split(gs_images, gs_labels, test_size=0.2, stratify=gs_labels, random_state=SEED)\n    \n    gs_model_names = ['EfficientNetB0', 'ResNet50', 'DenseNet121']\n    gs_results = []\n    \n    for model_name in gs_model_names:\n        model_file = f\"best_gs_fine_{model_name}.keras\"\n        if os.path.exists(model_file):\n            acc, prec, rec, f1, auc_val = evaluate_gs_model(model_file, X_test, y_test)\n            gs_results.append({\n                \"Model\": model_name,\n                \"Accuracy\": acc,\n                \"Precision\": prec,\n                \"Recall\": rec,\n                \"F1-Score\": f1,\n                \"AUC\": auc_val\n            })\n        else:\n            print(f\"Model file {model_file} not found.\")\n    \n    gs_results_df = pd.DataFrame(gs_results)\n    print(\"=== GS Detection Models Comparison ===\")\n    print(gs_results_df)\n    \n    # Evaluate symptom classification models\n    symptom_results = {}\n    for model_name in gs_model_names:\n        model_file = f\"best_symptom_{model_name}.keras\"\n        if os.path.exists(model_file):\n            report = evaluate_symptom_model(model_file, X_test_sym, y_test_sym)\n            symptom_results[model_name] = report\n        else:\n            print(f\"Model file {model_file} not found.\")\n    \n    # Summarize overall accuracy and weighted F1-score for symptom classification\n    symptom_summary = []\n    for model_name, report in symptom_results.items():\n        acc = report.get('accuracy', None)\n        weighted_f1 = report.get('weighted avg', {}).get('f1-score', None)\n        symptom_summary.append({\n            \"Model\": model_name,\n            \"Accuracy\": acc,\n            \"Weighted F1-Score\": weighted_f1\n        })\n    \n    symptom_summary_df = pd.DataFrame(symptom_summary)\n    print(\"\\n=== Symptom Classification Models Comparison ===\")\n    print(symptom_summary_df)\n\n# ===================== Main Execution =====================\nif __name__ == \"__main__\":\n    # Run training pipeline\n    train_pipeline()\n    \n    # After training, compare the results of the 3 models\n    compare_models()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:45:20.951037Z","iopub.execute_input":"2025-02-25T09:45:20.951352Z","iopub.status.idle":"2025-02-25T11:29:15.204103Z","shell.execute_reply.started":"2025-02-25T09:45:20.951324Z","shell.execute_reply":"2025-02-25T11:29:15.202232Z"}},"outputs":[{"name":"stdout","text":"Loaded 242 Cleft-Lip-and-Palate images\nLoaded 43 Epibulbar dermoid tumor images\nLoaded 20 Eyelid coloboma images\nLoaded 167 Facial asymmetry images\nLoaded 16 Malocclusion images\nLoaded 97 Microtia images\nLoaded 44 Vertebral abnormality images\nLoaded 2168 healthy images\n\n=== Training GS Detection Models ===\n\nTraining EfficientNetB0 for GS detection...\nFound 1790 validated image filenames belonging to 2 classes.\nFound 447 validated image filenames belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/40\n56/56 - 88s - 2s/step - accuracy: 0.7190 - auc: 0.5231 - loss: 0.5921 - precision: 0.3135 - recall: 0.1932 - val_accuracy: 0.8009 - val_auc: 0.6571 - val_loss: 1.1545 - val_precision: 0.8571 - val_recall: 0.0638 - learning_rate: 1.0000e-05\nEpoch 2/40\n56/56 - 34s - 608ms/step - accuracy: 0.7257 - auc: 0.5509 - loss: 0.5793 - precision: 0.3435 - recall: 0.2200 - val_accuracy: 0.8098 - val_auc: 0.7427 - val_loss: 1.1046 - val_precision: 0.9091 - val_recall: 0.1064 - learning_rate: 1.0000e-05\nEpoch 3/40\n56/56 - 35s - 629ms/step - accuracy: 0.7291 - auc: 0.5853 - loss: 0.5669 - precision: 0.3603 - recall: 0.2396 - val_accuracy: 0.8210 - val_auc: 0.7959 - val_loss: 1.0533 - val_precision: 0.9375 - val_recall: 0.1596 - learning_rate: 1.0000e-05\nEpoch 4/40\n56/56 - 37s - 662ms/step - accuracy: 0.7128 - auc: 0.5405 - loss: 0.5548 - precision: 0.3171 - recall: 0.2225 - val_accuracy: 0.8255 - val_auc: 0.8366 - val_loss: 1.0028 - val_precision: 0.9444 - val_recall: 0.1809 - learning_rate: 1.0000e-05\nEpoch 5/40\n56/56 - 37s - 662ms/step - accuracy: 0.7302 - auc: 0.5955 - loss: 0.5427 - precision: 0.3733 - recall: 0.2665 - val_accuracy: 0.8345 - val_auc: 0.8621 - val_loss: 0.9589 - val_precision: 0.9545 - val_recall: 0.2234 - learning_rate: 1.0000e-05\nEpoch 6/40\n56/56 - 37s - 658ms/step - accuracy: 0.7402 - auc: 0.6163 - loss: 0.5310 - precision: 0.4136 - recall: 0.3276 - val_accuracy: 0.8367 - val_auc: 0.8816 - val_loss: 0.9185 - val_precision: 1.0000 - val_recall: 0.2234 - learning_rate: 1.0000e-05\nEpoch 7/40\n56/56 - 37s - 664ms/step - accuracy: 0.7385 - auc: 0.6403 - loss: 0.5195 - precision: 0.4087 - recall: 0.3227 - val_accuracy: 0.8479 - val_auc: 0.8982 - val_loss: 0.8852 - val_precision: 1.0000 - val_recall: 0.2766 - learning_rate: 1.0000e-05\nEpoch 8/40\n56/56 - 37s - 656ms/step - accuracy: 0.7212 - auc: 0.6004 - loss: 0.5084 - precision: 0.3620 - recall: 0.2885 - val_accuracy: 0.8523 - val_auc: 0.9100 - val_loss: 0.8561 - val_precision: 1.0000 - val_recall: 0.2979 - learning_rate: 1.0000e-05\nEpoch 9/40\n56/56 - 37s - 658ms/step - accuracy: 0.7123 - auc: 0.6312 - loss: 0.4972 - precision: 0.3494 - recall: 0.3007 - val_accuracy: 0.8591 - val_auc: 0.9214 - val_loss: 0.8290 - val_precision: 1.0000 - val_recall: 0.3298 - learning_rate: 1.0000e-05\nEpoch 10/40\n56/56 - 37s - 656ms/step - accuracy: 0.7352 - auc: 0.6434 - loss: 0.4865 - precision: 0.3968 - recall: 0.3056 - val_accuracy: 0.8658 - val_auc: 0.9322 - val_loss: 0.8041 - val_precision: 1.0000 - val_recall: 0.3617 - learning_rate: 1.0000e-05\nEpoch 11/40\n56/56 - 34s - 612ms/step - accuracy: 0.7374 - auc: 0.6493 - loss: 0.4759 - precision: 0.4121 - recall: 0.3496 - val_accuracy: 0.8725 - val_auc: 0.9407 - val_loss: 0.7811 - val_precision: 1.0000 - val_recall: 0.3936 - learning_rate: 1.0000e-05\nEpoch 12/40\n56/56 - 32s - 580ms/step - accuracy: 0.7570 - auc: 0.6994 - loss: 0.4654 - precision: 0.4618 - recall: 0.3839 - val_accuracy: 0.8837 - val_auc: 0.9475 - val_loss: 0.7609 - val_precision: 1.0000 - val_recall: 0.4468 - learning_rate: 1.0000e-05\nEpoch 13/40\n56/56 - 32s - 577ms/step - accuracy: 0.7531 - auc: 0.6711 - loss: 0.4553 - precision: 0.4522 - recall: 0.3814 - val_accuracy: 0.8926 - val_auc: 0.9551 - val_loss: 0.7408 - val_precision: 1.0000 - val_recall: 0.4894 - learning_rate: 1.0000e-05\nEpoch 14/40\n56/56 - 33s - 583ms/step - accuracy: 0.7547 - auc: 0.7109 - loss: 0.4453 - precision: 0.4592 - recall: 0.4132 - val_accuracy: 0.9016 - val_auc: 0.9597 - val_loss: 0.7234 - val_precision: 1.0000 - val_recall: 0.5319 - learning_rate: 1.0000e-05\nEpoch 15/40\n56/56 - 33s - 582ms/step - accuracy: 0.7503 - auc: 0.6891 - loss: 0.4356 - precision: 0.4492 - recall: 0.4108 - val_accuracy: 0.9105 - val_auc: 0.9633 - val_loss: 0.7093 - val_precision: 1.0000 - val_recall: 0.5745 - learning_rate: 1.0000e-05\nEpoch 16/40\n56/56 - 32s - 576ms/step - accuracy: 0.7704 - auc: 0.7125 - loss: 0.4260 - precision: 0.4974 - recall: 0.4621 - val_accuracy: 0.9172 - val_auc: 0.9672 - val_loss: 0.6920 - val_precision: 1.0000 - val_recall: 0.6064 - learning_rate: 1.0000e-05\nEpoch 17/40\n56/56 - 33s - 589ms/step - accuracy: 0.7615 - auc: 0.7097 - loss: 0.4165 - precision: 0.4758 - recall: 0.4328 - val_accuracy: 0.9217 - val_auc: 0.9709 - val_loss: 0.6771 - val_precision: 1.0000 - val_recall: 0.6277 - learning_rate: 1.0000e-05\nEpoch 18/40\n56/56 - 36s - 644ms/step - accuracy: 0.7587 - auc: 0.6900 - loss: 0.4074 - precision: 0.4688 - recall: 0.4230 - val_accuracy: 0.9329 - val_auc: 0.9748 - val_loss: 0.6620 - val_precision: 1.0000 - val_recall: 0.6809 - learning_rate: 1.0000e-05\nEpoch 19/40\n56/56 - 38s - 679ms/step - accuracy: 0.7872 - auc: 0.7630 - loss: 0.3983 - precision: 0.5354 - recall: 0.5183 - val_accuracy: 0.9374 - val_auc: 0.9778 - val_loss: 0.6479 - val_precision: 1.0000 - val_recall: 0.7021 - learning_rate: 1.0000e-05\nEpoch 20/40\n56/56 - 38s - 681ms/step - accuracy: 0.7704 - auc: 0.7346 - loss: 0.3895 - precision: 0.4973 - recall: 0.4548 - val_accuracy: 0.9418 - val_auc: 0.9807 - val_loss: 0.6350 - val_precision: 1.0000 - val_recall: 0.7234 - learning_rate: 1.0000e-05\nEpoch 21/40\n56/56 - 39s - 692ms/step - accuracy: 0.7804 - auc: 0.7605 - loss: 0.3807 - precision: 0.5199 - recall: 0.5110 - val_accuracy: 0.9418 - val_auc: 0.9821 - val_loss: 0.6230 - val_precision: 1.0000 - val_recall: 0.7234 - learning_rate: 1.0000e-05\nEpoch 22/40\n56/56 - 38s - 686ms/step - accuracy: 0.7615 - auc: 0.7420 - loss: 0.3723 - precision: 0.4795 - recall: 0.5159 - val_accuracy: 0.9485 - val_auc: 0.9834 - val_loss: 0.6099 - val_precision: 1.0000 - val_recall: 0.7553 - learning_rate: 1.0000e-05\nEpoch 23/40\n56/56 - 38s - 680ms/step - accuracy: 0.7922 - auc: 0.7975 - loss: 0.3638 - precision: 0.5408 - recall: 0.5990 - val_accuracy: 0.9553 - val_auc: 0.9842 - val_loss: 0.5996 - val_precision: 1.0000 - val_recall: 0.7872 - learning_rate: 1.0000e-05\nEpoch 24/40\n56/56 - 37s - 665ms/step - accuracy: 0.7950 - auc: 0.8033 - loss: 0.3557 - precision: 0.5477 - recall: 0.5892 - val_accuracy: 0.9575 - val_auc: 0.9851 - val_loss: 0.5907 - val_precision: 1.0000 - val_recall: 0.7979 - learning_rate: 1.0000e-05\nEpoch 25/40\n56/56 - 37s - 668ms/step - accuracy: 0.7911 - auc: 0.7928 - loss: 0.3477 - precision: 0.5414 - recall: 0.5599 - val_accuracy: 0.9575 - val_auc: 0.9866 - val_loss: 0.5798 - val_precision: 1.0000 - val_recall: 0.7979 - learning_rate: 1.0000e-05\nEpoch 26/40\n56/56 - 37s - 664ms/step - accuracy: 0.7793 - auc: 0.7772 - loss: 0.3398 - precision: 0.5158 - recall: 0.5599 - val_accuracy: 0.9620 - val_auc: 0.9878 - val_loss: 0.5699 - val_precision: 1.0000 - val_recall: 0.8191 - learning_rate: 1.0000e-05\nEpoch 27/40\n56/56 - 38s - 671ms/step - accuracy: 0.7888 - auc: 0.8094 - loss: 0.3321 - precision: 0.5329 - recall: 0.6137 - val_accuracy: 0.9620 - val_auc: 0.9888 - val_loss: 0.5612 - val_precision: 1.0000 - val_recall: 0.8191 - learning_rate: 1.0000e-05\nEpoch 28/40\n56/56 - 37s - 653ms/step - accuracy: 0.7827 - auc: 0.7922 - loss: 0.3246 - precision: 0.5221 - recall: 0.5770 - val_accuracy: 0.9642 - val_auc: 0.9897 - val_loss: 0.5508 - val_precision: 1.0000 - val_recall: 0.8298 - learning_rate: 1.0000e-05\nEpoch 29/40\n56/56 - 36s - 644ms/step - accuracy: 0.7916 - auc: 0.8185 - loss: 0.3171 - precision: 0.5369 - recall: 0.6406 - val_accuracy: 0.9620 - val_auc: 0.9909 - val_loss: 0.5429 - val_precision: 0.9873 - val_recall: 0.8298 - learning_rate: 1.0000e-05\nEpoch 30/40\n56/56 - 36s - 642ms/step - accuracy: 0.7944 - auc: 0.8043 - loss: 0.3099 - precision: 0.5423 - recall: 0.6430 - val_accuracy: 0.9620 - val_auc: 0.9915 - val_loss: 0.5350 - val_precision: 0.9873 - val_recall: 0.8298 - learning_rate: 1.0000e-05\nEpoch 31/40\n56/56 - 37s - 654ms/step - accuracy: 0.7883 - auc: 0.8053 - loss: 0.3028 - precision: 0.5322 - recall: 0.6064 - val_accuracy: 0.9687 - val_auc: 0.9925 - val_loss: 0.5224 - val_precision: 0.9878 - val_recall: 0.8617 - learning_rate: 1.0000e-05\nEpoch 32/40\n56/56 - 36s - 650ms/step - accuracy: 0.8078 - auc: 0.8295 - loss: 0.2958 - precision: 0.5696 - recall: 0.6504 - val_accuracy: 0.9687 - val_auc: 0.9930 - val_loss: 0.5145 - val_precision: 0.9878 - val_recall: 0.8617 - learning_rate: 1.0000e-05\nEpoch 33/40\n56/56 - 37s - 659ms/step - accuracy: 0.8196 - auc: 0.8414 - loss: 0.2889 - precision: 0.5951 - recall: 0.6577 - val_accuracy: 0.9732 - val_auc: 0.9933 - val_loss: 0.5062 - val_precision: 0.9881 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 34/40\n56/56 - 36s - 645ms/step - accuracy: 0.8028 - auc: 0.8392 - loss: 0.2822 - precision: 0.5569 - recall: 0.6699 - val_accuracy: 0.9754 - val_auc: 0.9937 - val_loss: 0.4997 - val_precision: 0.9882 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 35/40\n56/56 - 37s - 655ms/step - accuracy: 0.8173 - auc: 0.8548 - loss: 0.2756 - precision: 0.5854 - recall: 0.6870 - val_accuracy: 0.9754 - val_auc: 0.9942 - val_loss: 0.4946 - val_precision: 0.9882 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 36/40\n56/56 - 36s - 647ms/step - accuracy: 0.8358 - auc: 0.8721 - loss: 0.2692 - precision: 0.6242 - recall: 0.7066 - val_accuracy: 0.9776 - val_auc: 0.9945 - val_loss: 0.4874 - val_precision: 0.9884 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 37/40\n56/56 - 36s - 651ms/step - accuracy: 0.8179 - auc: 0.8486 - loss: 0.2629 - precision: 0.5866 - recall: 0.6870 - val_accuracy: 0.9776 - val_auc: 0.9946 - val_loss: 0.4776 - val_precision: 0.9884 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 38/40\n56/56 - 37s - 653ms/step - accuracy: 0.8101 - auc: 0.8523 - loss: 0.2567 - precision: 0.5700 - recall: 0.6870 - val_accuracy: 0.9776 - val_auc: 0.9951 - val_loss: 0.4675 - val_precision: 0.9884 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 39/40\n56/56 - 37s - 660ms/step - accuracy: 0.8279 - auc: 0.8841 - loss: 0.2506 - precision: 0.5992 - recall: 0.7457 - val_accuracy: 0.9776 - val_auc: 0.9954 - val_loss: 0.4615 - val_precision: 0.9884 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 40/40\n56/56 - 36s - 651ms/step - accuracy: 0.8346 - auc: 0.8698 - loss: 0.2447 - precision: 0.6175 - recall: 0.7262 - val_accuracy: 0.9776 - val_auc: 0.9957 - val_loss: 0.4540 - val_precision: 0.9884 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 40/60\n56/56 - 82s - 1s/step - accuracy: 0.7810 - auc: 0.7985 - loss: 0.2415 - precision: 0.5168 - recall: 0.6406 - val_accuracy: 0.9687 - val_auc: 0.9956 - val_loss: 0.4584 - val_precision: 0.9878 - val_recall: 0.8617 - learning_rate: 1.0000e-06\nEpoch 41/60\n56/56 - 36s - 644ms/step - accuracy: 0.8017 - auc: 0.8270 - loss: 0.2408 - precision: 0.5558 - recall: 0.6577 - val_accuracy: 0.9620 - val_auc: 0.9948 - val_loss: 0.4641 - val_precision: 0.9873 - val_recall: 0.8298 - learning_rate: 1.0000e-06\nEpoch 42/60\n56/56 - 36s - 644ms/step - accuracy: 0.7810 - auc: 0.8020 - loss: 0.2401 - precision: 0.5178 - recall: 0.6039 - val_accuracy: 0.9575 - val_auc: 0.9924 - val_loss: 0.4680 - val_precision: 0.9870 - val_recall: 0.8085 - learning_rate: 1.0000e-06\nEpoch 43/60\n56/56 - 36s - 645ms/step - accuracy: 0.8123 - auc: 0.8333 - loss: 0.2394 - precision: 0.5734 - recall: 0.6968 - val_accuracy: 0.9553 - val_auc: 0.9894 - val_loss: 0.4701 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 1.0000e-06\nEpoch 44/60\n56/56 - 34s - 611ms/step - accuracy: 0.8084 - auc: 0.8316 - loss: 0.2387 - precision: 0.5708 - recall: 0.6504 - val_accuracy: 0.9553 - val_auc: 0.9883 - val_loss: 0.4703 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 1.0000e-06\nEpoch 45/60\n56/56 - 33s - 589ms/step - accuracy: 0.8011 - auc: 0.8206 - loss: 0.2380 - precision: 0.5521 - recall: 0.6870 - val_accuracy: 0.9553 - val_auc: 0.9870 - val_loss: 0.4693 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 1.0000e-06\nEpoch 46/60\n56/56 - 36s - 641ms/step - accuracy: 0.8028 - auc: 0.8303 - loss: 0.2376 - precision: 0.5586 - recall: 0.6528 - val_accuracy: 0.9553 - val_auc: 0.9866 - val_loss: 0.4689 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 2.0000e-07\nEpoch 47/60\n56/56 - 36s - 634ms/step - accuracy: 0.7944 - auc: 0.8190 - loss: 0.2375 - precision: 0.5421 - recall: 0.6455 - val_accuracy: 0.9553 - val_auc: 0.9865 - val_loss: 0.4689 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 2.0000e-07\nEpoch 48/60\n56/56 - 35s - 632ms/step - accuracy: 0.8123 - auc: 0.8379 - loss: 0.2373 - precision: 0.5759 - recall: 0.6773 - val_accuracy: 0.9553 - val_auc: 0.9864 - val_loss: 0.4694 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 2.0000e-07\nEpoch 49/60\n56/56 - 35s - 625ms/step - accuracy: 0.7978 - auc: 0.8272 - loss: 0.2372 - precision: 0.5495 - recall: 0.6381 - val_accuracy: 0.9553 - val_auc: 0.9864 - val_loss: 0.4685 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 2.0000e-07\nEpoch 50/60\n56/56 - 35s - 628ms/step - accuracy: 0.7961 - auc: 0.8265 - loss: 0.2371 - precision: 0.5438 - recall: 0.6675 - val_accuracy: 0.9553 - val_auc: 0.9863 - val_loss: 0.4686 - val_precision: 0.9744 - val_recall: 0.8085 - learning_rate: 2.0000e-07\nFound 560 validated image filenames belonging to 2 classes.\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 576ms/step\n\nEfficientNetB0 GS Detection Classification Report:\n              precision    recall  f1-score   support\n\n     Healthy       0.95      0.99      0.97       434\n          GS       0.95      0.82      0.88       126\n\n    accuracy                           0.95       560\n   macro avg       0.95      0.90      0.92       560\nweighted avg       0.95      0.95      0.95       560\n\n\nTraining ResNet50 for GS detection...\nFound 1790 validated image filenames belonging to 2 classes.\nFound 447 validated image filenames belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/40\n56/56 - 66s - 1s/step - accuracy: 0.4335 - auc: 0.3820 - loss: 0.6192 - precision: 0.1758 - recall: 0.4010 - val_accuracy: 0.1477 - val_auc: 0.1471 - val_loss: 1.9624 - val_precision: 0.1385 - val_recall: 0.5851 - learning_rate: 1.0000e-05\nEpoch 2/40\n56/56 - 38s - 672ms/step - accuracy: 0.4637 - auc: 0.4560 - loss: 0.6035 - precision: 0.2097 - recall: 0.4866 - val_accuracy: 0.1969 - val_auc: 0.2386 - val_loss: 1.8262 - val_precision: 0.1429 - val_recall: 0.5638 - learning_rate: 1.0000e-05\nEpoch 3/40\n56/56 - 38s - 677ms/step - accuracy: 0.4715 - auc: 0.4659 - loss: 0.5882 - precision: 0.2097 - recall: 0.4743 - val_accuracy: 0.2662 - val_auc: 0.3478 - val_loss: 1.7234 - val_precision: 0.1657 - val_recall: 0.6170 - learning_rate: 1.0000e-05\nEpoch 4/40\n56/56 - 37s - 668ms/step - accuracy: 0.4827 - auc: 0.5090 - loss: 0.5732 - precision: 0.2327 - recall: 0.5501 - val_accuracy: 0.3289 - val_auc: 0.4541 - val_loss: 1.6335 - val_precision: 0.1916 - val_recall: 0.6809 - learning_rate: 1.0000e-05\nEpoch 5/40\n56/56 - 37s - 667ms/step - accuracy: 0.5106 - auc: 0.5486 - loss: 0.5586 - precision: 0.2503 - recall: 0.5721 - val_accuracy: 0.3870 - val_auc: 0.5457 - val_loss: 1.5700 - val_precision: 0.2239 - val_recall: 0.7766 - learning_rate: 1.0000e-05\nEpoch 6/40\n56/56 - 38s - 670ms/step - accuracy: 0.5190 - auc: 0.5708 - loss: 0.5445 - precision: 0.2591 - recall: 0.5941 - val_accuracy: 0.4206 - val_auc: 0.6249 - val_loss: 1.5437 - val_precision: 0.2430 - val_recall: 0.8298 - learning_rate: 1.0000e-05\nEpoch 7/40\n56/56 - 37s - 667ms/step - accuracy: 0.5564 - auc: 0.5956 - loss: 0.5306 - precision: 0.2800 - recall: 0.5990 - val_accuracy: 0.4228 - val_auc: 0.6873 - val_loss: 1.5316 - val_precision: 0.2515 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 8/40\n56/56 - 38s - 672ms/step - accuracy: 0.5810 - auc: 0.6579 - loss: 0.5170 - precision: 0.3078 - recall: 0.6675 - val_accuracy: 0.4295 - val_auc: 0.7304 - val_loss: 1.5174 - val_precision: 0.2553 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 9/40\n56/56 - 38s - 674ms/step - accuracy: 0.5844 - auc: 0.6840 - loss: 0.5037 - precision: 0.3153 - recall: 0.6993 - val_accuracy: 0.4407 - val_auc: 0.7681 - val_loss: 1.5086 - val_precision: 0.2636 - val_recall: 0.9255 - learning_rate: 1.0000e-05\nEpoch 10/40\n56/56 - 37s - 667ms/step - accuracy: 0.5525 - auc: 0.6511 - loss: 0.4909 - precision: 0.2932 - recall: 0.6797 - val_accuracy: 0.4609 - val_auc: 0.8052 - val_loss: 1.4726 - val_precision: 0.2752 - val_recall: 0.9574 - learning_rate: 1.0000e-05\nEpoch 11/40\n56/56 - 38s - 674ms/step - accuracy: 0.5894 - auc: 0.6834 - loss: 0.4783 - precision: 0.3164 - recall: 0.6870 - val_accuracy: 0.4653 - val_auc: 0.8283 - val_loss: 1.4467 - val_precision: 0.2769 - val_recall: 0.9574 - learning_rate: 1.0000e-05\nEpoch 12/40\n56/56 - 38s - 687ms/step - accuracy: 0.5877 - auc: 0.7135 - loss: 0.4660 - precision: 0.3202 - recall: 0.7164 - val_accuracy: 0.4944 - val_auc: 0.8531 - val_loss: 1.3758 - val_precision: 0.2898 - val_recall: 0.9681 - learning_rate: 1.0000e-05\nEpoch 13/40\n56/56 - 38s - 680ms/step - accuracy: 0.6268 - auc: 0.7477 - loss: 0.4539 - precision: 0.3517 - recall: 0.7506 - val_accuracy: 0.5056 - val_auc: 0.8696 - val_loss: 1.3401 - val_precision: 0.2932 - val_recall: 0.9574 - learning_rate: 1.0000e-05\nEpoch 14/40\n56/56 - 38s - 674ms/step - accuracy: 0.6078 - auc: 0.7285 - loss: 0.4423 - precision: 0.3345 - recall: 0.7237 - val_accuracy: 0.5145 - val_auc: 0.8851 - val_loss: 1.3062 - val_precision: 0.2970 - val_recall: 0.9574 - learning_rate: 1.0000e-05\nEpoch 15/40\n56/56 - 37s - 660ms/step - accuracy: 0.6285 - auc: 0.7638 - loss: 0.4308 - precision: 0.3555 - recall: 0.7702 - val_accuracy: 0.5503 - val_auc: 0.8997 - val_loss: 1.2569 - val_precision: 0.3149 - val_recall: 0.9681 - learning_rate: 1.0000e-05\nEpoch 16/40\n56/56 - 34s - 612ms/step - accuracy: 0.6492 - auc: 0.7912 - loss: 0.4196 - precision: 0.3749 - recall: 0.8020 - val_accuracy: 0.5570 - val_auc: 0.9104 - val_loss: 1.2362 - val_precision: 0.3182 - val_recall: 0.9681 - learning_rate: 1.0000e-05\nEpoch 17/40\n56/56 - 35s - 620ms/step - accuracy: 0.6480 - auc: 0.7713 - loss: 0.4088 - precision: 0.3695 - recall: 0.7653 - val_accuracy: 0.5884 - val_auc: 0.9245 - val_loss: 1.1762 - val_precision: 0.3346 - val_recall: 0.9681 - learning_rate: 1.0000e-05\nEpoch 18/40\n56/56 - 33s - 595ms/step - accuracy: 0.6587 - auc: 0.7948 - loss: 0.3981 - precision: 0.3795 - recall: 0.7775 - val_accuracy: 0.5973 - val_auc: 0.9329 - val_loss: 1.1505 - val_precision: 0.3396 - val_recall: 0.9681 - learning_rate: 1.0000e-05\nEpoch 19/40\n56/56 - 35s - 617ms/step - accuracy: 0.6754 - auc: 0.8096 - loss: 0.3877 - precision: 0.3964 - recall: 0.8044 - val_accuracy: 0.6152 - val_auc: 0.9416 - val_loss: 1.1138 - val_precision: 0.3511 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 20/40\n56/56 - 37s - 655ms/step - accuracy: 0.6609 - auc: 0.8044 - loss: 0.3776 - precision: 0.3846 - recall: 0.8068 - val_accuracy: 0.6264 - val_auc: 0.9489 - val_loss: 1.0836 - val_precision: 0.3591 - val_recall: 0.9894 - learning_rate: 1.0000e-05\nEpoch 21/40\n56/56 - 38s - 672ms/step - accuracy: 0.6927 - auc: 0.8385 - loss: 0.3676 - precision: 0.4137 - recall: 0.8264 - val_accuracy: 0.6353 - val_auc: 0.9546 - val_loss: 1.0408 - val_precision: 0.3636 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 22/40\n56/56 - 36s - 636ms/step - accuracy: 0.6899 - auc: 0.8500 - loss: 0.3580 - precision: 0.4127 - recall: 0.8435 - val_accuracy: 0.6711 - val_auc: 0.9598 - val_loss: 0.9846 - val_precision: 0.3882 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 23/40\n56/56 - 36s - 641ms/step - accuracy: 0.6872 - auc: 0.8574 - loss: 0.3485 - precision: 0.4104 - recall: 0.8460 - val_accuracy: 0.6868 - val_auc: 0.9637 - val_loss: 0.9443 - val_precision: 0.4000 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 24/40\n56/56 - 36s - 646ms/step - accuracy: 0.7067 - auc: 0.8666 - loss: 0.3393 - precision: 0.4289 - recall: 0.8557 - val_accuracy: 0.6935 - val_auc: 0.9669 - val_loss: 0.9211 - val_precision: 0.4053 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 25/40\n56/56 - 36s - 650ms/step - accuracy: 0.7279 - auc: 0.8690 - loss: 0.3303 - precision: 0.4494 - recall: 0.8460 - val_accuracy: 0.7092 - val_auc: 0.9711 - val_loss: 0.8853 - val_precision: 0.4182 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 26/40\n56/56 - 37s - 665ms/step - accuracy: 0.7380 - auc: 0.8494 - loss: 0.3216 - precision: 0.4601 - recall: 0.8460 - val_accuracy: 0.7181 - val_auc: 0.9723 - val_loss: 0.8660 - val_precision: 0.4259 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 27/40\n56/56 - 36s - 650ms/step - accuracy: 0.7464 - auc: 0.8882 - loss: 0.3130 - precision: 0.4707 - recall: 0.8826 - val_accuracy: 0.7315 - val_auc: 0.9749 - val_loss: 0.8431 - val_precision: 0.4381 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 28/40\n56/56 - 37s - 652ms/step - accuracy: 0.7352 - auc: 0.8880 - loss: 0.3047 - precision: 0.4578 - recall: 0.8631 - val_accuracy: 0.7494 - val_auc: 0.9777 - val_loss: 0.8007 - val_precision: 0.4554 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 29/40\n56/56 - 37s - 655ms/step - accuracy: 0.7682 - auc: 0.9146 - loss: 0.2965 - precision: 0.4960 - recall: 0.9193 - val_accuracy: 0.7785 - val_auc: 0.9791 - val_loss: 0.7673 - val_precision: 0.4868 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 30/40\n56/56 - 37s - 655ms/step - accuracy: 0.7765 - auc: 0.8979 - loss: 0.2886 - precision: 0.5064 - recall: 0.8753 - val_accuracy: 0.7785 - val_auc: 0.9803 - val_loss: 0.7455 - val_precision: 0.4868 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 31/40\n56/56 - 36s - 646ms/step - accuracy: 0.7642 - auc: 0.9063 - loss: 0.2808 - precision: 0.4912 - recall: 0.8826 - val_accuracy: 0.7919 - val_auc: 0.9816 - val_loss: 0.7209 - val_precision: 0.5027 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 32/40\n56/56 - 36s - 649ms/step - accuracy: 0.7732 - auc: 0.9208 - loss: 0.2732 - precision: 0.5020 - recall: 0.9046 - val_accuracy: 0.8031 - val_auc: 0.9825 - val_loss: 0.7000 - val_precision: 0.5169 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 33/40\n56/56 - 37s - 659ms/step - accuracy: 0.7872 - auc: 0.9286 - loss: 0.2659 - precision: 0.5197 - recall: 0.9022 - val_accuracy: 0.8054 - val_auc: 0.9832 - val_loss: 0.6843 - val_precision: 0.5198 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 34/40\n56/56 - 36s - 650ms/step - accuracy: 0.7810 - auc: 0.9270 - loss: 0.2587 - precision: 0.5116 - recall: 0.9144 - val_accuracy: 0.8076 - val_auc: 0.9837 - val_loss: 0.6717 - val_precision: 0.5227 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 35/40\n56/56 - 35s - 620ms/step - accuracy: 0.7872 - auc: 0.9279 - loss: 0.2517 - precision: 0.5196 - recall: 0.9095 - val_accuracy: 0.8300 - val_auc: 0.9844 - val_loss: 0.6368 - val_precision: 0.5542 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 36/40\n56/56 - 33s - 596ms/step - accuracy: 0.8095 - auc: 0.9419 - loss: 0.2448 - precision: 0.5493 - recall: 0.9267 - val_accuracy: 0.8523 - val_auc: 0.9856 - val_loss: 0.6163 - val_precision: 0.5897 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 37/40\n56/56 - 32s - 573ms/step - accuracy: 0.7983 - auc: 0.9250 - loss: 0.2382 - precision: 0.5346 - recall: 0.9071 - val_accuracy: 0.8456 - val_auc: 0.9858 - val_loss: 0.6037 - val_precision: 0.5786 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 38/40\n56/56 - 32s - 574ms/step - accuracy: 0.8056 - auc: 0.9386 - loss: 0.2316 - precision: 0.5449 - recall: 0.9046 - val_accuracy: 0.8523 - val_auc: 0.9862 - val_loss: 0.5907 - val_precision: 0.5897 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 39/40\n56/56 - 32s - 577ms/step - accuracy: 0.8123 - auc: 0.9350 - loss: 0.2253 - precision: 0.5547 - recall: 0.9046 - val_accuracy: 0.8680 - val_auc: 0.9871 - val_loss: 0.5682 - val_precision: 0.6174 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 40/40\n56/56 - 32s - 579ms/step - accuracy: 0.8251 - auc: 0.9497 - loss: 0.2191 - precision: 0.5721 - recall: 0.9315 - val_accuracy: 0.8702 - val_auc: 0.9880 - val_loss: 0.5536 - val_precision: 0.6216 - val_recall: 0.9787 - learning_rate: 1.0000e-05\nEpoch 40/60\n56/56 - 56s - 993ms/step - accuracy: 0.8140 - auc: 0.9431 - loss: 0.2157 - precision: 0.5565 - recall: 0.9144 - val_accuracy: 0.8859 - val_auc: 0.9880 - val_loss: 0.5470 - val_precision: 0.6525 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 41/60\n56/56 - 31s - 556ms/step - accuracy: 0.8257 - auc: 0.9437 - loss: 0.2149 - precision: 0.5740 - recall: 0.9193 - val_accuracy: 0.8971 - val_auc: 0.9875 - val_loss: 0.5377 - val_precision: 0.6765 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 42/60\n56/56 - 31s - 559ms/step - accuracy: 0.8112 - auc: 0.9432 - loss: 0.2141 - precision: 0.5521 - recall: 0.9193 - val_accuracy: 0.9016 - val_auc: 0.9872 - val_loss: 0.5323 - val_precision: 0.6866 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 43/60\n56/56 - 31s - 560ms/step - accuracy: 0.8140 - auc: 0.9418 - loss: 0.2134 - precision: 0.5576 - recall: 0.8998 - val_accuracy: 0.9016 - val_auc: 0.9877 - val_loss: 0.5259 - val_precision: 0.6866 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 44/60\n56/56 - 31s - 558ms/step - accuracy: 0.8089 - auc: 0.9450 - loss: 0.2126 - precision: 0.5483 - recall: 0.9291 - val_accuracy: 0.9038 - val_auc: 0.9879 - val_loss: 0.5221 - val_precision: 0.6917 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 45/60\n56/56 - 31s - 561ms/step - accuracy: 0.8279 - auc: 0.9463 - loss: 0.2119 - precision: 0.5778 - recall: 0.9169 - val_accuracy: 0.9038 - val_auc: 0.9877 - val_loss: 0.5182 - val_precision: 0.6917 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 46/60\n56/56 - 31s - 562ms/step - accuracy: 0.8028 - auc: 0.9370 - loss: 0.2112 - precision: 0.5401 - recall: 0.9218 - val_accuracy: 0.9105 - val_auc: 0.9881 - val_loss: 0.5106 - val_precision: 0.7077 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 47/60\n56/56 - 32s - 563ms/step - accuracy: 0.8179 - auc: 0.9516 - loss: 0.2104 - precision: 0.5618 - recall: 0.9218 - val_accuracy: 0.9105 - val_auc: 0.9884 - val_loss: 0.5041 - val_precision: 0.7077 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 48/60\n56/56 - 31s - 558ms/step - accuracy: 0.8263 - auc: 0.9605 - loss: 0.2096 - precision: 0.5731 - recall: 0.9389 - val_accuracy: 0.9105 - val_auc: 0.9882 - val_loss: 0.5025 - val_precision: 0.7077 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 49/60\n56/56 - 31s - 558ms/step - accuracy: 0.8374 - auc: 0.9468 - loss: 0.2089 - precision: 0.5928 - recall: 0.9218 - val_accuracy: 0.9128 - val_auc: 0.9886 - val_loss: 0.5017 - val_precision: 0.7132 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 50/60\n56/56 - 32s - 564ms/step - accuracy: 0.8223 - auc: 0.9516 - loss: 0.2082 - precision: 0.5670 - recall: 0.9413 - val_accuracy: 0.9128 - val_auc: 0.9885 - val_loss: 0.4961 - val_precision: 0.7132 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 51/60\n56/56 - 32s - 566ms/step - accuracy: 0.8257 - auc: 0.9446 - loss: 0.2075 - precision: 0.5734 - recall: 0.9267 - val_accuracy: 0.9172 - val_auc: 0.9887 - val_loss: 0.4881 - val_precision: 0.7244 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 52/60\n56/56 - 31s - 555ms/step - accuracy: 0.8268 - auc: 0.9571 - loss: 0.2067 - precision: 0.5738 - recall: 0.9413 - val_accuracy: 0.9217 - val_auc: 0.9888 - val_loss: 0.4845 - val_precision: 0.7360 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 53/60\n56/56 - 31s - 559ms/step - accuracy: 0.8341 - auc: 0.9588 - loss: 0.2060 - precision: 0.5851 - recall: 0.9413 - val_accuracy: 0.9195 - val_auc: 0.9888 - val_loss: 0.4822 - val_precision: 0.7302 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 54/60\n56/56 - 30s - 543ms/step - accuracy: 0.8391 - auc: 0.9559 - loss: 0.2053 - precision: 0.5924 - recall: 0.9487 - val_accuracy: 0.9217 - val_auc: 0.9886 - val_loss: 0.4824 - val_precision: 0.7360 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 55/60\n56/56 - 31s - 559ms/step - accuracy: 0.8380 - auc: 0.9562 - loss: 0.2046 - precision: 0.5920 - recall: 0.9364 - val_accuracy: 0.9195 - val_auc: 0.9887 - val_loss: 0.4817 - val_precision: 0.7302 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 56/60\n56/56 - 31s - 562ms/step - accuracy: 0.8385 - auc: 0.9539 - loss: 0.2038 - precision: 0.5949 - recall: 0.9193 - val_accuracy: 0.9239 - val_auc: 0.9886 - val_loss: 0.4755 - val_precision: 0.7419 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 57/60\n56/56 - 32s - 564ms/step - accuracy: 0.8525 - auc: 0.9635 - loss: 0.2031 - precision: 0.6153 - recall: 0.9462 - val_accuracy: 0.9239 - val_auc: 0.9887 - val_loss: 0.4713 - val_precision: 0.7419 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 58/60\n56/56 - 32s - 563ms/step - accuracy: 0.8464 - auc: 0.9636 - loss: 0.2024 - precision: 0.6050 - recall: 0.9438 - val_accuracy: 0.9239 - val_auc: 0.9890 - val_loss: 0.4696 - val_precision: 0.7419 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 59/60\n56/56 - 32s - 570ms/step - accuracy: 0.8408 - auc: 0.9631 - loss: 0.2017 - precision: 0.5948 - recall: 0.9511 - val_accuracy: 0.9284 - val_auc: 0.9890 - val_loss: 0.4649 - val_precision: 0.7541 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nEpoch 60/60\n56/56 - 30s - 543ms/step - accuracy: 0.8542 - auc: 0.9661 - loss: 0.2010 - precision: 0.6164 - recall: 0.9584 - val_accuracy: 0.9284 - val_auc: 0.9890 - val_loss: 0.4670 - val_precision: 0.7541 - val_recall: 0.9787 - learning_rate: 1.0000e-06\nFound 560 validated image filenames belonging to 2 classes.\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step\n\nResNet50 GS Detection Classification Report:\n              precision    recall  f1-score   support\n\n     Healthy       1.00      0.93      0.96       434\n          GS       0.80      0.98      0.88       126\n\n    accuracy                           0.94       560\n   macro avg       0.90      0.96      0.92       560\nweighted avg       0.95      0.94      0.94       560\n\n\nTraining DenseNet121 for GS detection...\nFound 1790 validated image filenames belonging to 2 classes.\nFound 447 validated image filenames belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/40\n56/56 - 83s - 1s/step - accuracy: 0.5078 - auc: 0.4711 - loss: 0.5731 - precision: 0.2143 - recall: 0.4328 - val_accuracy: 0.7383 - val_auc: 0.3281 - val_loss: 1.2351 - val_precision: 0.0741 - val_recall: 0.0213 - learning_rate: 1.0000e-05\nEpoch 2/40\n56/56 - 32s - 572ms/step - accuracy: 0.5430 - auc: 0.4805 - loss: 0.5615 - precision: 0.2334 - recall: 0.4377 - val_accuracy: 0.6532 - val_auc: 0.4314 - val_loss: 1.2253 - val_precision: 0.1980 - val_recall: 0.2128 - learning_rate: 1.0000e-05\nEpoch 3/40\n56/56 - 32s - 572ms/step - accuracy: 0.5469 - auc: 0.5200 - loss: 0.5500 - precision: 0.2456 - recall: 0.4743 - val_accuracy: 0.6331 - val_auc: 0.5305 - val_loss: 1.2111 - val_precision: 0.2603 - val_recall: 0.4043 - learning_rate: 1.0000e-05\nEpoch 4/40\n56/56 - 32s - 573ms/step - accuracy: 0.5296 - auc: 0.4928 - loss: 0.5390 - precision: 0.2311 - recall: 0.4548 - val_accuracy: 0.6309 - val_auc: 0.5990 - val_loss: 1.1954 - val_precision: 0.2874 - val_recall: 0.5106 - learning_rate: 1.0000e-05\nEpoch 5/40\n56/56 - 32s - 576ms/step - accuracy: 0.5324 - auc: 0.5008 - loss: 0.5281 - precision: 0.2312 - recall: 0.4499 - val_accuracy: 0.6398 - val_auc: 0.6379 - val_loss: 1.1843 - val_precision: 0.3169 - val_recall: 0.6170 - learning_rate: 1.0000e-05\nEpoch 6/40\n56/56 - 33s - 590ms/step - accuracy: 0.5397 - auc: 0.5356 - loss: 0.5173 - precision: 0.2448 - recall: 0.4866 - val_accuracy: 0.6443 - val_auc: 0.6757 - val_loss: 1.1719 - val_precision: 0.3350 - val_recall: 0.7021 - learning_rate: 1.0000e-05\nEpoch 7/40\n56/56 - 33s - 585ms/step - accuracy: 0.5564 - auc: 0.5652 - loss: 0.5068 - precision: 0.2573 - recall: 0.4988 - val_accuracy: 0.6353 - val_auc: 0.7045 - val_loss: 1.1583 - val_precision: 0.3333 - val_recall: 0.7340 - learning_rate: 1.0000e-05\nEpoch 8/40\n56/56 - 33s - 590ms/step - accuracy: 0.5765 - auc: 0.5535 - loss: 0.4966 - precision: 0.2701 - recall: 0.5012 - val_accuracy: 0.6532 - val_auc: 0.7311 - val_loss: 1.1339 - val_precision: 0.3498 - val_recall: 0.7553 - learning_rate: 1.0000e-05\nEpoch 9/40\n56/56 - 32s - 577ms/step - accuracy: 0.5704 - auc: 0.5620 - loss: 0.4865 - precision: 0.2727 - recall: 0.5281 - val_accuracy: 0.6443 - val_auc: 0.7432 - val_loss: 1.1212 - val_precision: 0.3430 - val_recall: 0.7553 - learning_rate: 1.0000e-05\nEpoch 10/40\n56/56 - 33s - 583ms/step - accuracy: 0.5670 - auc: 0.5767 - loss: 0.4766 - precision: 0.2695 - recall: 0.5232 - val_accuracy: 0.6644 - val_auc: 0.7613 - val_loss: 1.1033 - val_precision: 0.3600 - val_recall: 0.7660 - learning_rate: 1.0000e-05\nEpoch 11/40\n56/56 - 32s - 575ms/step - accuracy: 0.5743 - auc: 0.5913 - loss: 0.4669 - precision: 0.2757 - recall: 0.5306 - val_accuracy: 0.6711 - val_auc: 0.7730 - val_loss: 1.0853 - val_precision: 0.3655 - val_recall: 0.7660 - learning_rate: 1.0000e-05\nEpoch 12/40\n56/56 - 32s - 571ms/step - accuracy: 0.5771 - auc: 0.6253 - loss: 0.4574 - precision: 0.2924 - recall: 0.5990 - val_accuracy: 0.6689 - val_auc: 0.7823 - val_loss: 1.0789 - val_precision: 0.3622 - val_recall: 0.7553 - learning_rate: 1.0000e-05\nEpoch 13/40\n56/56 - 32s - 572ms/step - accuracy: 0.5872 - auc: 0.6144 - loss: 0.4481 - precision: 0.2958 - recall: 0.5844 - val_accuracy: 0.6689 - val_auc: 0.7986 - val_loss: 1.0608 - val_precision: 0.3676 - val_recall: 0.7979 - learning_rate: 1.0000e-05\nEpoch 14/40\n56/56 - 32s - 566ms/step - accuracy: 0.5765 - auc: 0.6118 - loss: 0.4390 - precision: 0.2880 - recall: 0.5795 - val_accuracy: 0.6532 - val_auc: 0.8125 - val_loss: 1.0579 - val_precision: 0.3555 - val_recall: 0.7979 - learning_rate: 1.0000e-05\nEpoch 15/40\n56/56 - 32s - 568ms/step - accuracy: 0.6112 - auc: 0.6488 - loss: 0.4299 - precision: 0.3181 - recall: 0.6137 - val_accuracy: 0.6801 - val_auc: 0.8261 - val_loss: 1.0443 - val_precision: 0.3805 - val_recall: 0.8298 - learning_rate: 1.0000e-05\nEpoch 16/40\n56/56 - 32s - 573ms/step - accuracy: 0.6017 - auc: 0.6517 - loss: 0.4211 - precision: 0.3109 - recall: 0.6112 - val_accuracy: 0.6801 - val_auc: 0.8355 - val_loss: 1.0251 - val_precision: 0.3816 - val_recall: 0.8404 - learning_rate: 1.0000e-05\nEpoch 17/40\n56/56 - 32s - 567ms/step - accuracy: 0.6117 - auc: 0.6856 - loss: 0.4125 - precision: 0.3298 - recall: 0.6773 - val_accuracy: 0.6846 - val_auc: 0.8439 - val_loss: 1.0110 - val_precision: 0.3854 - val_recall: 0.8404 - learning_rate: 1.0000e-05\nEpoch 18/40\n56/56 - 32s - 574ms/step - accuracy: 0.6246 - auc: 0.6854 - loss: 0.4040 - precision: 0.3350 - recall: 0.6528 - val_accuracy: 0.6957 - val_auc: 0.8601 - val_loss: 0.9918 - val_precision: 0.3960 - val_recall: 0.8511 - learning_rate: 1.0000e-05\nEpoch 19/40\n56/56 - 32s - 568ms/step - accuracy: 0.6207 - auc: 0.6783 - loss: 0.3957 - precision: 0.3291 - recall: 0.6357 - val_accuracy: 0.6846 - val_auc: 0.8664 - val_loss: 0.9826 - val_precision: 0.3865 - val_recall: 0.8511 - learning_rate: 1.0000e-05\nEpoch 20/40\n56/56 - 32s - 564ms/step - accuracy: 0.6128 - auc: 0.6780 - loss: 0.3875 - precision: 0.3243 - recall: 0.6406 - val_accuracy: 0.7002 - val_auc: 0.8693 - val_loss: 0.9637 - val_precision: 0.4010 - val_recall: 0.8617 - learning_rate: 1.0000e-05\nEpoch 21/40\n56/56 - 34s - 604ms/step - accuracy: 0.6335 - auc: 0.6996 - loss: 0.3795 - precision: 0.3462 - recall: 0.6797 - val_accuracy: 0.7002 - val_auc: 0.8807 - val_loss: 0.9502 - val_precision: 0.4010 - val_recall: 0.8617 - learning_rate: 1.0000e-05\nEpoch 22/40\n56/56 - 32s - 571ms/step - accuracy: 0.6397 - auc: 0.7089 - loss: 0.3716 - precision: 0.3475 - recall: 0.6577 - val_accuracy: 0.7047 - val_auc: 0.8820 - val_loss: 0.9439 - val_precision: 0.4059 - val_recall: 0.8723 - learning_rate: 1.0000e-05\nEpoch 23/40\n56/56 - 32s - 580ms/step - accuracy: 0.6302 - auc: 0.7016 - loss: 0.3638 - precision: 0.3425 - recall: 0.6724 - val_accuracy: 0.7069 - val_auc: 0.8821 - val_loss: 0.9328 - val_precision: 0.4080 - val_recall: 0.8723 - learning_rate: 1.0000e-05\nEpoch 24/40\n56/56 - 32s - 567ms/step - accuracy: 0.6397 - auc: 0.7009 - loss: 0.3563 - precision: 0.3499 - recall: 0.6724 - val_accuracy: 0.7025 - val_auc: 0.8889 - val_loss: 0.9213 - val_precision: 0.4039 - val_recall: 0.8723 - learning_rate: 1.0000e-05\nEpoch 25/40\n56/56 - 32s - 575ms/step - accuracy: 0.6575 - auc: 0.7319 - loss: 0.3488 - precision: 0.3668 - recall: 0.6870 - val_accuracy: 0.7136 - val_auc: 0.8916 - val_loss: 0.9133 - val_precision: 0.4150 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 26/40\n56/56 - 32s - 566ms/step - accuracy: 0.6542 - auc: 0.7323 - loss: 0.3415 - precision: 0.3681 - recall: 0.7164 - val_accuracy: 0.7092 - val_auc: 0.8944 - val_loss: 0.9005 - val_precision: 0.4109 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 27/40\n56/56 - 32s - 570ms/step - accuracy: 0.6464 - auc: 0.7483 - loss: 0.3343 - precision: 0.3634 - recall: 0.7286 - val_accuracy: 0.7092 - val_auc: 0.8991 - val_loss: 0.8901 - val_precision: 0.4109 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 28/40\n56/56 - 32s - 568ms/step - accuracy: 0.6637 - auc: 0.7490 - loss: 0.3272 - precision: 0.3774 - recall: 0.7262 - val_accuracy: 0.7204 - val_auc: 0.9007 - val_loss: 0.8835 - val_precision: 0.4213 - val_recall: 0.8830 - learning_rate: 1.0000e-05\nEpoch 29/40\n56/56 - 32s - 571ms/step - accuracy: 0.6810 - auc: 0.7684 - loss: 0.3203 - precision: 0.3945 - recall: 0.7408 - val_accuracy: 0.7271 - val_auc: 0.9093 - val_loss: 0.8679 - val_precision: 0.4293 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 30/40\n56/56 - 32s - 573ms/step - accuracy: 0.6760 - auc: 0.7859 - loss: 0.3135 - precision: 0.3946 - recall: 0.7824 - val_accuracy: 0.7360 - val_auc: 0.9147 - val_loss: 0.8611 - val_precision: 0.4381 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 31/40\n56/56 - 32s - 571ms/step - accuracy: 0.6581 - auc: 0.7530 - loss: 0.3068 - precision: 0.3736 - recall: 0.7335 - val_accuracy: 0.7405 - val_auc: 0.9162 - val_loss: 0.8474 - val_precision: 0.4421 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 32/40\n56/56 - 32s - 574ms/step - accuracy: 0.6944 - auc: 0.7905 - loss: 0.3002 - precision: 0.4106 - recall: 0.7751 - val_accuracy: 0.7494 - val_auc: 0.9136 - val_loss: 0.8394 - val_precision: 0.4516 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 33/40\n56/56 - 33s - 589ms/step - accuracy: 0.6927 - auc: 0.7636 - loss: 0.2939 - precision: 0.4025 - recall: 0.7115 - val_accuracy: 0.7584 - val_auc: 0.9196 - val_loss: 0.8214 - val_precision: 0.4615 - val_recall: 0.8936 - learning_rate: 1.0000e-05\nEpoch 34/40\n56/56 - 32s - 575ms/step - accuracy: 0.6899 - auc: 0.7974 - loss: 0.2875 - precision: 0.4047 - recall: 0.7579 - val_accuracy: 0.7629 - val_auc: 0.9187 - val_loss: 0.8185 - val_precision: 0.4670 - val_recall: 0.9043 - learning_rate: 1.0000e-05\nEpoch 35/40\n56/56 - 32s - 574ms/step - accuracy: 0.7073 - auc: 0.8157 - loss: 0.2813 - precision: 0.4240 - recall: 0.7848 - val_accuracy: 0.7673 - val_auc: 0.9226 - val_loss: 0.8108 - val_precision: 0.4728 - val_recall: 0.9255 - learning_rate: 1.0000e-05\nEpoch 36/40\n56/56 - 33s - 582ms/step - accuracy: 0.6939 - auc: 0.7966 - loss: 0.2752 - precision: 0.4089 - recall: 0.7628 - val_accuracy: 0.7740 - val_auc: 0.9243 - val_loss: 0.7986 - val_precision: 0.4804 - val_recall: 0.9149 - learning_rate: 1.0000e-05\nEpoch 37/40\n56/56 - 32s - 572ms/step - accuracy: 0.6844 - auc: 0.7844 - loss: 0.2692 - precision: 0.3974 - recall: 0.7384 - val_accuracy: 0.7808 - val_auc: 0.9260 - val_loss: 0.7887 - val_precision: 0.4888 - val_recall: 0.9255 - learning_rate: 1.0000e-05\nEpoch 38/40\n56/56 - 32s - 573ms/step - accuracy: 0.7095 - auc: 0.8056 - loss: 0.2633 - precision: 0.4234 - recall: 0.7506 - val_accuracy: 0.7852 - val_auc: 0.9296 - val_loss: 0.7746 - val_precision: 0.4944 - val_recall: 0.9362 - learning_rate: 1.0000e-05\nEpoch 39/40\n56/56 - 32s - 566ms/step - accuracy: 0.7246 - auc: 0.8200 - loss: 0.2576 - precision: 0.4434 - recall: 0.8044 - val_accuracy: 0.7875 - val_auc: 0.9330 - val_loss: 0.7704 - val_precision: 0.4972 - val_recall: 0.9362 - learning_rate: 1.0000e-05\nEpoch 40/40\n56/56 - 32s - 572ms/step - accuracy: 0.6994 - auc: 0.8139 - loss: 0.2519 - precision: 0.4148 - recall: 0.7677 - val_accuracy: 0.7830 - val_auc: 0.9326 - val_loss: 0.7659 - val_precision: 0.4916 - val_recall: 0.9362 - learning_rate: 1.0000e-05\nEpoch 40/60\n56/56 - 73s - 1s/step - accuracy: 0.6184 - auc: 0.6678 - loss: 0.2489 - precision: 0.3230 - recall: 0.6112 - val_accuracy: 0.2729 - val_auc: 0.8641 - val_loss: 1.0828 - val_precision: 0.2190 - val_recall: 0.9574 - learning_rate: 1.0000e-06\nEpoch 41/60\n56/56 - 32s - 567ms/step - accuracy: 0.6330 - auc: 0.6962 - loss: 0.2483 - precision: 0.3450 - recall: 0.6748 - val_accuracy: 0.2998 - val_auc: 0.8786 - val_loss: 1.0411 - val_precision: 0.2269 - val_recall: 0.9681 - learning_rate: 1.0000e-06\nEpoch 42/60\n56/56 - 31s - 558ms/step - accuracy: 0.6374 - auc: 0.7047 - loss: 0.2476 - precision: 0.3489 - recall: 0.6773 - val_accuracy: 0.3490 - val_auc: 0.8867 - val_loss: 0.9977 - val_precision: 0.2401 - val_recall: 0.9681 - learning_rate: 1.0000e-06\nEpoch 43/60\n56/56 - 32s - 564ms/step - accuracy: 0.6374 - auc: 0.7081 - loss: 0.2469 - precision: 0.3504 - recall: 0.6870 - val_accuracy: 0.4385 - val_auc: 0.8902 - val_loss: 0.9592 - val_precision: 0.2671 - val_recall: 0.9574 - learning_rate: 1.0000e-06\nEpoch 44/60\n56/56 - 31s - 560ms/step - accuracy: 0.6413 - auc: 0.7015 - loss: 0.2463 - precision: 0.3501 - recall: 0.6650 - val_accuracy: 0.4966 - val_auc: 0.8979 - val_loss: 0.9268 - val_precision: 0.2866 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 45/60\n56/56 - 32s - 567ms/step - accuracy: 0.6492 - auc: 0.7107 - loss: 0.2456 - precision: 0.3569 - recall: 0.6675 - val_accuracy: 0.5526 - val_auc: 0.9022 - val_loss: 0.8965 - val_precision: 0.3121 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 46/60\n56/56 - 32s - 568ms/step - accuracy: 0.6291 - auc: 0.6998 - loss: 0.2450 - precision: 0.3408 - recall: 0.6675 - val_accuracy: 0.6130 - val_auc: 0.9088 - val_loss: 0.8720 - val_precision: 0.3451 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 47/60\n56/56 - 32s - 567ms/step - accuracy: 0.6307 - auc: 0.6955 - loss: 0.2444 - precision: 0.3385 - recall: 0.6455 - val_accuracy: 0.6510 - val_auc: 0.9154 - val_loss: 0.8494 - val_precision: 0.3697 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 48/60\n56/56 - 31s - 561ms/step - accuracy: 0.6385 - auc: 0.7201 - loss: 0.2437 - precision: 0.3520 - recall: 0.6919 - val_accuracy: 0.6756 - val_auc: 0.9200 - val_loss: 0.8290 - val_precision: 0.3886 - val_recall: 0.9468 - learning_rate: 1.0000e-06\nEpoch 49/60\n56/56 - 32s - 563ms/step - accuracy: 0.6520 - auc: 0.7213 - loss: 0.2431 - precision: 0.3607 - recall: 0.6773 - val_accuracy: 0.7159 - val_auc: 0.9239 - val_loss: 0.8138 - val_precision: 0.4218 - val_recall: 0.9468 - learning_rate: 1.0000e-06\nEpoch 50/60\n56/56 - 32s - 563ms/step - accuracy: 0.6441 - auc: 0.7301 - loss: 0.2424 - precision: 0.3586 - recall: 0.7066 - val_accuracy: 0.7226 - val_auc: 0.9251 - val_loss: 0.8034 - val_precision: 0.4279 - val_recall: 0.9468 - learning_rate: 1.0000e-06\nEpoch 51/60\n56/56 - 32s - 565ms/step - accuracy: 0.6749 - auc: 0.7298 - loss: 0.2418 - precision: 0.3845 - recall: 0.7042 - val_accuracy: 0.7315 - val_auc: 0.9261 - val_loss: 0.7965 - val_precision: 0.4356 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 52/60\n56/56 - 32s - 567ms/step - accuracy: 0.6497 - auc: 0.7188 - loss: 0.2412 - precision: 0.3617 - recall: 0.6968 - val_accuracy: 0.7383 - val_auc: 0.9278 - val_loss: 0.7870 - val_precision: 0.4416 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 53/60\n56/56 - 32s - 563ms/step - accuracy: 0.6587 - auc: 0.7243 - loss: 0.2406 - precision: 0.3718 - recall: 0.7164 - val_accuracy: 0.7405 - val_auc: 0.9281 - val_loss: 0.7818 - val_precision: 0.4439 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 54/60\n56/56 - 32s - 567ms/step - accuracy: 0.6654 - auc: 0.7479 - loss: 0.2399 - precision: 0.3747 - recall: 0.6944 - val_accuracy: 0.7472 - val_auc: 0.9295 - val_loss: 0.7805 - val_precision: 0.4508 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 55/60\n56/56 - 31s - 561ms/step - accuracy: 0.6536 - auc: 0.7525 - loss: 0.2392 - precision: 0.3666 - recall: 0.7090 - val_accuracy: 0.7562 - val_auc: 0.9311 - val_loss: 0.7725 - val_precision: 0.4607 - val_recall: 0.9362 - learning_rate: 1.0000e-06\nEpoch 56/60\n56/56 - 32s - 575ms/step - accuracy: 0.6704 - auc: 0.7500 - loss: 0.2386 - precision: 0.3817 - recall: 0.7139 - val_accuracy: 0.7629 - val_auc: 0.9322 - val_loss: 0.7663 - val_precision: 0.4677 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 57/60\n56/56 - 32s - 563ms/step - accuracy: 0.6670 - auc: 0.7445 - loss: 0.2380 - precision: 0.3762 - recall: 0.6944 - val_accuracy: 0.7606 - val_auc: 0.9338 - val_loss: 0.7639 - val_precision: 0.4652 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 58/60\n56/56 - 30s - 544ms/step - accuracy: 0.6609 - auc: 0.7557 - loss: 0.2374 - precision: 0.3737 - recall: 0.7164 - val_accuracy: 0.7651 - val_auc: 0.9344 - val_loss: 0.7643 - val_precision: 0.4703 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 59/60\n56/56 - 32s - 571ms/step - accuracy: 0.6553 - auc: 0.7432 - loss: 0.2368 - precision: 0.3693 - recall: 0.7188 - val_accuracy: 0.7651 - val_auc: 0.9358 - val_loss: 0.7589 - val_precision: 0.4703 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nEpoch 60/60\n56/56 - 32s - 569ms/step - accuracy: 0.6626 - auc: 0.7429 - loss: 0.2362 - precision: 0.3755 - recall: 0.7188 - val_accuracy: 0.7651 - val_auc: 0.9378 - val_loss: 0.7583 - val_precision: 0.4703 - val_recall: 0.9255 - learning_rate: 1.0000e-06\nFound 560 validated image filenames belonging to 2 classes.\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 686ms/step\n\nDenseNet121 GS Detection Classification Report:\n              precision    recall  f1-score   support\n\n     Healthy       0.97      0.71      0.82       434\n          GS       0.48      0.94      0.64       126\n\n    accuracy                           0.76       560\n   macro avg       0.73      0.82      0.73       560\nweighted avg       0.86      0.76      0.78       560\n\n\n=== Training Symptom Classifier ===\n\nTraining EfficientNetB0 for symptom classification...\nFound 1356 validated image filenames belonging to 7 classes.\nFound 338 validated image filenames belonging to 7 classes.\nEpoch 1/40\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-86d2c67306b1>\u001b[0m in \u001b[0;36m<cell line: 428>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;31m# Run training pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# After training, compare the results of the 3 models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-86d2c67306b1>\u001b[0m in \u001b[0;36mtrain_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         history = model.fit(\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node LogicalAnd defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,32] vs. [1,224]\n\t [[{{node LogicalAnd}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_563796[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_564531]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node LogicalAnd defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,32] vs. [1,224]\n\t [[{{node LogicalAnd}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_563796[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_564531]","output_type":"error"}],"execution_count":1}]}